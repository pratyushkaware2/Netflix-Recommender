{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHsMzk8sgJhc",
        "outputId": "051cc2a5-fa64-4a91-e7ac-db3eedfd4cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RamhppWbmZ3W"
      },
      "source": [
        "# **Collaborative Filtering**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d00XXVSSEWQc"
      },
      "source": [
        "### Reading comma-separated values using pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCO2-RLPmkoi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/DATASET/TrainingRatings.txt\", sep = ',', header = None,)\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/DATASET/TestingRatings.txt\", sep = ',', header = None,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVI2pheEEe9H"
      },
      "source": [
        "### Encoding the user ids and movie ids so there are no missing rows and columns, its easy to form a matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAupMn4Rf-2C"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le_mov, le_usr = [LabelEncoder(),LabelEncoder()] \n",
        "\n",
        "df[0] = le_mov.fit_transform(df[0])\n",
        "df_test[0] = le_mov.transform(df_test[0])\n",
        "df[1] = le_usr.fit_transform(df[1])\n",
        "df_test[1] = le_usr.transform(df_test[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh0O62reFYsL"
      },
      "source": [
        "### Grouping by user ids and get their average rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luv5vNRkf2mj",
        "outputId": "051f1ec6-408f-42c2-b915-7c277bcf0fd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1821, 28978)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "grouped_by_user_test = df_test.groupby(1, group_keys=True)\n",
        "userid_keys_test = grouped_by_user_test.groups.keys()\n",
        "temp = []\n",
        "for uids in userid_keys_test:\n",
        "  temp.append([uids, len(grouped_by_user_test.get_group(uids))]) \n",
        "\n",
        "grouped_by_user = df.groupby(1, group_keys=True)\n",
        "userid_keys = grouped_by_user.groups.keys()\n",
        "(len(set(df[0])),len(userid_keys))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsBrNvGcIm64"
      },
      "source": [
        "### Creating Average rating vector for each user id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5J5C6C1IGsS",
        "outputId": "5234bdcf-bbe7-4891-e271-e0a71ae662bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28978, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "avg_rating_user_vi = np.zeros((len(userid_keys),1), dtype = 'float32')\n",
        "movie_id_userid_matrix_vij = np.zeros((len(set(df[0])),len(userid_keys),), dtype='float32')\n",
        "for userid in userid_keys:\n",
        "  avg_rating_user_vi[userid,0] = grouped_by_user.get_group(userid)[2].sum()/(len(grouped_by_user.get_group(userid)))\n",
        "print(avg_rating_user_vi.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY6h5mssJIsv"
      },
      "source": [
        "### Creating user id x movie id matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSVA2eJQMPCs"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "for index, row in df.iterrows():\n",
        "  movie_id_userid_matrix_vij[int(row[0]),int(row[1])] = row[2]\n",
        "\n",
        "# op_path = '/content/drive/MyDrive/DATASET/'\n",
        "# p_out = open(op_path + 'train_data.pickle','wb')\n",
        "# pickle.dump(movie_id_userid_matrix_vij, p_out)\n",
        "# p_out.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ra_1dreIU8_"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# op_path = '/content/drive/MyDrive/DATASET/'\n",
        "# movie_id_userid_matrix_vij = pickle.load(open(op_path + 'train_data.pickle','rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5eGwUl_Iy4w"
      },
      "source": [
        "### **Using KD Tree to get approximate 10000 neighbors** (users with similar ratings based on euclidean distance). \n",
        "### Takes about 60 minutes to finish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gR6vJDbGCWT"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KDTree, BallTree\n",
        "import sklearn.metrics.pairwise as smp\n",
        "kdt_pearson = KDTree(np.transpose(movie_id_userid_matrix_vij), leaf_size=30, metric='euclidean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNfKPCkSL7Ur",
        "outputId": "3a05dbf2-58a6-48b8-9dc8-3c2641dd4d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14 : 2.3744153022766112\n",
            "15 : 2.4343807339668273\n",
            "16 : 2.505748999118805\n",
            "17 : 2.415492955843608\n",
            "18 : 2.336666436990102\n",
            "19 : 2.31311270793279\n",
            "20 : 2.3396354635556538\n",
            "21 : 2.490177396933238\n",
            "22 : 2.3689947287241617\n",
            "23 : 2.3420947154362994\n",
            "24 : 2.3773436307907105\n",
            "25 : 2.5081828037897744\n",
            "26 : 2.3523050904273988\n",
            "27 : 2.4273357431093854\n",
            "28 : 2.3359150886535645\n"
          ]
        }
      ],
      "source": [
        "from time import time\n",
        "nearest_neighbors = [0]*30\n",
        "distances = [0]*30\n",
        "\n",
        "# op_path = '/content/drive/MyDrive/DATASET/'\n",
        "for i in range(29):\n",
        "  st = time()\n",
        "  distances[i], nearest_neighbors[i] = kdt_pearson.query(np.transpose(movie_id_userid_matrix_vij)[1000*i:1000*i+1000,:], k=10000, return_distance=True)\n",
        "  print(i,\":\",(time() - st)/60)\n",
        "  # p_out = open(op_path + 'nearest_neighbors1.pickle','wb')\n",
        "  # pickle.dump(nearest_neighbors, p_out)\n",
        "  # p_out.close()\n",
        "  # p_out = open(op_path + 'distances1.pickle','wb')\n",
        "  # pickle.dump(distances, p_out)\n",
        "  # p_out.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKLi3vwzLWnO"
      },
      "source": [
        "### Calculating weight matrix based on the pearson coefficient and cosine distance between the 100 nearest users found. Takes about 28~30 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2Ig1H4qqa6T"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# op_path = '/content/drive/MyDrive/DATASET/'\n",
        "# distancs = pickle.load(open(op_path + 'distances.pickle','rb'))\n",
        "# distancs1 = pickle.load(open(op_path + 'distances1.pickle','rb'))\n",
        "# nearest_neighbors = distancs[:14]+distancs1[14:29]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI_VN_9DrAos"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from time import time\n",
        "from scipy import spatial\n",
        "from scipy.stats import pearsonr  \n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "weights_corr = np.zeros((28978, 101, 1))\n",
        "weights_cosign = np.zeros((28978, 101, 1))\n",
        "vals = 0\n",
        "st = time()\n",
        "for part in nearest_neighbors:\n",
        "  for nns in part:\n",
        "    for i, nn in enumerate(nns[1:102]):\n",
        "      weights_corr[nns[0],i] = (np.corrcoef(np.transpose(movie_id_userid_matrix_vij)[nn,:],np.transpose(movie_id_userid_matrix_vij)[nns[0],:]))[0,1]\n",
        "      weights_cosign[nns[0], i] = spatial.distance.cosine(np.transpose(movie_id_userid_matrix_vij)[nn,:],np.transpose(movie_id_userid_matrix_vij)[nns[0],:])\n",
        "      \n",
        "      vals += 1\n",
        "      if(vals > 100000):\n",
        "        vals = 0\n",
        "        print('Time Taken:', (time()-st)/60, \"min\")\n",
        "        # p_out = open(op_path + 'bkp_corr.pickle','wb')\n",
        "        # pickle.dump(weights_corr, p_out)\n",
        "        # p_out.close()\n",
        "        # p_out = open(op_path + 'bkp_cos.pickle','wb')\n",
        "        # pickle.dump(weights_cosign, p_out)\n",
        "        # p_out.close()\n",
        "        st = time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_xYjn6HNenp"
      },
      "source": [
        "### Calculating normalizing factor K for correlation weights and cosine weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhR16N8fmAtA"
      },
      "outputs": [],
      "source": [
        "# p_out = open(op_path + 'bkp_cos.pickle','rb')\n",
        "# weights_cosign = pickle.load(p_out)\n",
        "# p_out.close()\n",
        "\n",
        "# p_out = open(op_path + 'bkp_corr.pickle','rb')\n",
        "# weights_corr = pickle.load(p_out)\n",
        "# p_out.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXW1BQCqeizA",
        "outputId": "fe08fe33-aa32-4685-bcdc-6bef73e048a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-3a1dd75ee76c>:7: RuntimeWarning: invalid value encountered in true_divide\n",
            "  norm_weights_corr[i,:] = abs(wt_arr)/np.sum(abs(wt_arr))\n"
          ]
        }
      ],
      "source": [
        "norm_weights_corr = np.zeros((28978, 101, 1))\n",
        "norm_weights_cosine = np.zeros((28978, 101, 1))\n",
        "# weights_cosign = -(weights_cosign-1)\n",
        "K_corr = 0\n",
        "K_cos = 0\n",
        "for i, wt_arr in enumerate(weights_corr):\n",
        "  norm_weights_corr[i,:] = abs(wt_arr)/np.sum(abs(wt_arr))\n",
        "  K_corr += np.sum(abs(wt_arr))\n",
        "\n",
        "for i, wt_arr in enumerate(weights_cosign):\n",
        "  norm_weights_cosine[i,:] = abs(wt_arr)/np.sum(abs(wt_arr))\n",
        "  K_cos += np.sum(abs(wt_arr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El7yzGxiN76J"
      },
      "source": [
        "### Calculating the difference between a users movie rating and their average rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9or7Yxok16z"
      },
      "outputs": [],
      "source": [
        "v_diff_matrix = np.zeros((len(set(df[0])),len(userid_keys),), dtype='float32')\n",
        "for i in range(len(avg_rating_user_vi)):\n",
        "  v_diff_matrix[:, i] = movie_id_userid_matrix_vij[:,i] - avg_rating_user_vi[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ktk9xncPoLz"
      },
      "source": [
        "### **Predicting values for user id and movie id pairs in the test dataset and compare with actual rating.**\n",
        "### 1.   Predicting using Correlation and Cosine weights.\n",
        "### 2.   Finding accuracy based on exact value, 1.0 error, 1.5 error and binary classification just for reccommendation purposes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAHjsJIQmBhD",
        "outputId": "954f41b5-b1c1-4fc7-f19c-697a77673a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Correlation Weights:\n",
            "Mean Absolute Error 0.7902306948553648\n",
            "Root Mean Squared Error: 0.9886975382052426\n",
            "Accuracy for predicting the Exact Value: 38.74380461394534\n",
            "Accuracy for predicting with error of 1.0: 69.03401739684308\n",
            "Accuracy for predicting with error of 1.5: 87.00113457672326\n",
            "Accuracy for predicting Binary rating <>2.5: 83.94374888035192\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "row_num = -1\n",
        "t, f = [0,0,0,0], [0,0,0,0]\n",
        "n = len(df_test[0])\n",
        "err_mae = 0\n",
        "err_rmse = 0\n",
        "for idx, row in df_test.iterrows():\n",
        "  # row_num += 1\n",
        "  mid, uid, act_rat = int(row[0]), int(row[1]), row[2]\n",
        "  influence = 0\n",
        "  for i, nn in enumerate(nearest_neighbors[uid//1000][uid%1000][1:101]):\n",
        "    influence += abs(weights_corr[uid,i])*(movie_id_userid_matrix_vij[mid, nn] - avg_rating_user_vi[nn])\n",
        "  predict_rat = max(0, min(5.0, float(avg_rating_user_vi[uid] + (1/K_corr)*influence)))\n",
        "  \n",
        "  err_mae += abs(act_rat - predict_rat)\n",
        "  err_rmse += (act_rat - predict_rat)*(act_rat - predict_rat)\n",
        "\n",
        "  if(round(predict_rat)==act_rat):\n",
        "    t[0] += 1\n",
        "  else:\n",
        "    f[0] += 1\n",
        "\n",
        "  if(abs(act_rat - predict_rat) <= 1):\n",
        "    t[1] += 1\n",
        "  else:\n",
        "    f[1] += 1\n",
        "\n",
        "  if(abs(act_rat - predict_rat) <= 1.5):\n",
        "    t[2] += 1\n",
        "  else:\n",
        "    f[2] += 1\n",
        "\n",
        "  if(predict_rat <= 2.5 and act_rat <= 2.5) or (predict_rat > 2.5 and act_rat > 2.5):\n",
        "    t[3] += 1\n",
        "  else:\n",
        "    f[3] += 1\n",
        "\n",
        "print(\"For Correlation Weights:\")\n",
        "print(\"Mean Absolute Error\",err_mae/n)\n",
        "print(\"Root Mean Squared Error:\",math.sqrt(err_rmse/n))\n",
        "print(\"Accuracy for predicting the Exact Value:\", 100*t[0]/(t[0]+f[0]))\n",
        "print(\"Accuracy for predicting with error of 1.0:\", 100*t[1]/(t[1]+f[1]))\n",
        "print(\"Accuracy for predicting with error of 1.5:\", 100*t[2]/(t[2]+f[2]))\n",
        "print(\"Accuracy for predicting Binary rating <>2.5:\", 100*t[3]/(t[3]+f[3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OehRtWiV31U",
        "outputId": "99f81895-5abd-4156-cb20-5886bfde613c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Cosine Similarity Weights:\n",
            "Mean Absolute Error 1.520541810147495\n",
            "Root Mean Squared Error: 1.8681189547001045\n",
            "Accuracy for predicting the Exact Value: 19.028045940404866\n",
            "Accuracy for predicting with error of 1.0: 50.97135691395131\n",
            "Accuracy for predicting with error of 1.5: 50.97135691395131\n",
            "Accuracy for predicting Binary rating <>2.5: 83.27693624475009\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "row_num = -1\n",
        "t, f = [0,0,0,0], [0,0,0,0]\n",
        "n = len(df_test[0])\n",
        "err_mae = 0\n",
        "err_rmse = 0\n",
        "\n",
        "for idx, row in df_test.iterrows():\n",
        "  mid, uid, act_rat = int(row[0]), int(row[1]), row[2]\n",
        "  influence = 0\n",
        "  for i, nn in enumerate(nearest_neighbors[uid//1000][uid%1000][1:101]):\n",
        "    influence += abs(weights_cosign[uid,i])*(movie_id_userid_matrix_vij[mid, nn] - avg_rating_user_vi[nn])\n",
        "  predict_rat = max(0, min(5.0, float(avg_rating_user_vi[uid] + (1/K_cos)*influence)))\n",
        "  \n",
        "  err_mae += abs(act_rat - predict_rat)\n",
        "  err_rmse += (act_rat - predict_rat)*(act_rat - predict_rat)\n",
        "\n",
        "  if(round(predict_rat)==act_rat):\n",
        "    t[0] += 1\n",
        "  else:\n",
        "    f[0] += 1\n",
        "\n",
        "  if(abs(act_rat - predict_rat) <= 1):\n",
        "    t[1] += 1\n",
        "  else:\n",
        "    f[1] += 1\n",
        "\n",
        "  if(abs(act_rat - predict_rat) <= 1.5):\n",
        "    t[2] += 1\n",
        "  else:\n",
        "    f[2] += 1\n",
        "\n",
        "  if(predict_rat <= 2.5 and act_rat <= 2.5) or (predict_rat > 2.5 and act_rat > 2.5):\n",
        "    t[3] += 1\n",
        "  else:\n",
        "    f[3] += 1\n",
        "\n",
        "print(\"For Cosine Similarity Weights:\")\n",
        "print(\"Mean Absolute Error\",err_mae/n)\n",
        "print(\"Root Mean Squared Error:\",math.sqrt(err_rmse/n))\n",
        "print(\"Accuracy for predicting the Exact Value:\", 100*t[0]/(t[0]+f[0]))\n",
        "print(\"Accuracy for predicting with error of 1.0:\", 100*t[1]/(t[1]+f[1]))\n",
        "print(\"Accuracy for predicting with error of 1.5:\", 100*t[2]/(t[2]+f[2]))\n",
        "print(\"Accuracy for predicting Binary rating <>2.5:\", 100*t[3]/(t[3]+f[3]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}